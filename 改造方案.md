# Dify 工作流日志获取脚本工程化改造方案

## 一、改造目标

将单体命令行脚本改造成符合生产环境的定时任务系统，具备：
- ✅ 任务调度和监控（Prefect）
- ✅ 参数化配置（支持多环境、多任务实例）
- ✅ 结构化日志和错误追踪
- ✅ 模块化架构（易于维护和扩展）
- ✅ 结果存储和通知机制
- ✅ 重试和容错机制

---

## 二、架构设计

### 2.1 整体架构

```
┌─────────────────────────────────────────────────────────┐
│                    Prefect Server (UI)                   │
│              - 任务调度管理                               │
│              - 执行状态监控                               │
│              - 参数配置                                   │
└─────────────────────────────────────────────────────────┘
                          │
                          ▼
┌─────────────────────────────────────────────────────────┐
│                    Prefect Worker                         │
│              - 执行 Flow 任务                            │
│              - 工作池管理                                │
└─────────────────────────────────────────────────────────┘
                          │
                          ▼
┌─────────────────────────────────────────────────────────┐
│               Dify Workflow Log Service                   │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  │
│  │   Config     │  │   Fetcher    │  │   Reporter   │  │
│  │   Manager    │  │   Service    │  │   Service    │  │
│  └──────────────┘  └──────────────┘  └──────────────┘  │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  │
│  │   Logger     │  │   Storage    │  │  Notifier    │  │
│  │   Service    │  │   Service    │  │  Service     │  │
│  └──────────────┘  └──────────────┘  └──────────────┘  │
└─────────────────────────────────────────────────────────┘
                          │
                          ▼
┌─────────────────────────────────────────────────────────┐
│                    Dify API                              │
│              - Service API                                │
│              - Console API                                │
└─────────────────────────────────────────────────────────┘
```

### 2.2 核心组件

1. **Flow Layer（Prefect）**：任务编排层
   - `fetch_workflow_logs_flow`: 主流程
   - `fetch_logs_task`: 获取日志任务
   - `enrich_logs_task`: 丰富日志详情任务
   - `generate_reports_task`: 生成报告任务

2. **Service Layer（业务逻辑层）**：
   - `WorkflowLogFetcher`: 日志获取服务（保留原有逻辑）
   - `ReportGenerator`: 报告生成服务
   - `ConfigManager`: 配置管理服务
   - `StorageService`: 结果存储服务
   - `NotificationService`: 通知服务

3. **Infrastructure Layer（基础设施层）**：
   - `Logger`: 结构化日志
   - `RetryHandler`: 重试机制
   - `ErrorHandler`: 错误处理

---

## 三、目录结构

```
01-dify运维监控/
├── README.md                          # 项目说明
├── requirements.txt                   # Python 依赖
├── .env.example                       # 环境变量模板
├── config/
│   ├── __init__.py
│   ├── settings.py                    # 配置管理（支持环境变量）
│   └── deployments.yaml              # Deployment 配置模板
├── src/
│   ├── __init__.py
│   ├── core/
│   │   ├── __init__.py
│   │   ├── config.py                 # 配置管理类
│   │   ├── logger.py                 # 日志配置
│   │   └── exceptions.py             # 自定义异常
│   ├── services/
│   │   ├── __init__.py
│   │   ├── fetcher.py                # WorkflowLogFetcher（重构）
│   │   ├── reporter.py               # 报告生成服务
│   │   ├── storage.py                # 存储服务（本地/OSS/S3）
│   │   └── notifier.py               # 通知服务（邮件/钉钉/企业微信）
│   ├── utils/
│   │   ├── __init__.py
│   │   ├── retry.py                  # 重试装饰器
│   │   └── validators.py             # 参数校验
│   └── flows/
│       ├── __init__.py
│       ├── workflow_log_flow.py      # 主 Flow
│       └── tasks/
│           ├── __init__.py
│           ├── fetch_task.py         # 获取日志 Task
│           ├── enrich_task.py        # 丰富详情 Task
│           └── report_task.py        # 生成报告 Task
├── deployments/
│   ├── __init__.py
│   ├── daily_report.py               # 每日报告 Deployment
│   ├── weekly_report.py               # 每周报告 Deployment
│   └── custom_report.py               # 自定义报告 Deployment
├── scripts/
│   ├── setup_prefect.sh              # Prefect 初始化脚本
│   └── deploy.sh                     # 部署脚本
├── tests/
│   ├── __init__.py
│   ├── test_fetcher.py
│   ├── test_reporter.py
│   └── test_flows.py
└── outputs/                          # 输出目录（gitignore）
    ├── logs/                         # 执行日志
    ├── reports/                      # 生成的报告
    └── data/                         # 原始数据备份
```

---

## 四、核心模块设计

### 4.1 配置管理（`src/core/config.py`）

**设计要点**：
- 支持环境变量（`.env` 文件）
- 支持配置文件（YAML/JSON）
- 支持多环境（dev/staging/prod）
- 敏感信息加密存储

**配置结构**：
```python
class DifyConfig:
    # API 配置
    base_url: str
    api_token: str
    console_email: Optional[str]
    console_password: Optional[str]
    
    # 应用配置
    app_id: str
    
    # 输出配置
    output_dir: str
    storage_type: str  # local/oss/s3
    storage_config: dict
    
    # 通知配置
    notification_enabled: bool
    notification_type: str  # email/dingtalk/wechat
    notification_config: dict
    
    # 任务配置
    fetch_all: bool
    max_pages: Optional[int]
    with_details: bool
    with_node_executions: bool
```

### 4.2 日志服务（`src/core/logger.py`）

**设计要点**：
- 使用 `structlog` 或 `loguru` 实现结构化日志
- 支持日志级别、格式、输出目标配置
- 集成 Prefect 日志系统
- 支持日志文件轮转

**日志格式**：
```json
{
  "timestamp": "2024-01-01T12:00:00",
  "level": "INFO",
  "task_id": "xxx",
  "flow_run_id": "yyy",
  "message": "开始获取日志",
  "metadata": {...}
}
```

### 4.3 重试机制（`src/utils/retry.py`）

**设计要点**：
- 支持指数退避
- 可配置重试次数和条件
- 支持 Prefect 任务重试

**示例**：
```python
@retry(
    max_attempts=3,
    retry_on=(requests.RequestException,),
    backoff_factor=2
)
def fetch_logs(...):
    ...
```

### 4.4 存储服务（`src/services/storage.py`）

**设计要点**：
- 支持多种存储后端（本地文件、OSS、S3）
- 统一的存储接口
- 支持文件版本管理
- 自动清理旧文件

**接口**：
```python
class StorageService:
    def save_report(self, content: bytes, filename: str, report_type: str) -> str
    def save_data(self, data: dict, filename: str) -> str
    def list_reports(self, report_type: str, days: int) -> List[str]
    def cleanup_old_files(self, days: int) -> int
```

### 4.5 通知服务（`src/services/notifier.py`）

**设计要点**：
- 支持多种通知渠道（邮件、钉钉、企业微信）
- 任务成功/失败通知
- 报告生成完成通知
- 可配置通知模板

**接口**：
```python
class NotificationService:
    def notify_success(self, task_name: str, result: dict) -> bool
    def notify_failure(self, task_name: str, error: Exception) -> bool
    def notify_report_ready(self, report_path: str, report_type: str) -> bool
```

### 4.6 Flow 设计（`src/flows/workflow_log_flow.py`）

**设计要点**：
- 使用 Prefect 2.x Flow 和 Task 装饰器
- 参数化设计，支持 UI 配置
- 任务依赖关系清晰
- 支持并发执行

**Flow 结构**：
```python
@flow(name="fetch-workflow-logs")
def fetch_workflow_logs_flow(
    # 过滤参数
    keyword: Optional[str] = None,
    status: Optional[str] = None,
    created_at_before: Optional[str] = None,
    created_at_after: Optional[str] = None,
    # 输出配置
    output_format: str = "csv",  # csv/markdown/json
    output_dir: str = "./outputs",
    # 功能开关
    with_details: bool = True,
    with_node_executions: bool = True,
    # 通知配置
    notify_on_complete: bool = True,
) -> Dict[str, Any]:
    # Task 1: 获取日志
    logs = fetch_logs_task(
        keyword=keyword,
        status=status,
        created_at_before=created_at_before,
        created_at_after=created_at_after,
    )
    
    # Task 2: 丰富详情（可选）
    if with_details:
        enriched_logs = enrich_logs_task(logs, with_node_executions)
    else:
        enriched_logs = logs
    
    # Task 3: 生成报告
    report_paths = generate_reports_task(
        enriched_logs,
        output_format=output_format,
        output_dir=output_dir,
    )
    
    # Task 4: 发送通知（可选）
    if notify_on_complete:
        notify_completion_task(report_paths)
    
    return {
        "logs_count": len(enriched_logs),
        "report_paths": report_paths,
    }
```

---

## 五、Deployment 配置

### 5.1 每日报告 Deployment（`deployments/daily_report.py`）

```python
from prefect import serve
from src.flows.workflow_log_flow import fetch_workflow_logs_flow
from datetime import datetime, timedelta

if __name__ == "__main__":
    # 计算时间范围（昨天）
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%dT00:00:00Z")
    today = datetime.now().strftime("%Y-%m-%dT00:00:00Z")
    
    fetch_workflow_logs_flow.serve(
        name="daily-workflow-report",
        cron="0 2 * * *",  # 每天 02:00 执行
        parameters={
            "created_at_after": yesterday,
            "created_at_before": today,
            "output_format": "csv",
            "output_dir": "./outputs/reports/daily",
            "with_details": True,
            "with_node_executions": True,
            "notify_on_complete": True,
        },
        tags=["daily", "report", "workflow"],
        work_pool_name="dify-workflow-pool",
    )
```

### 5.2 每周报告 Deployment

```python
# 每周一生成上周的报告
fetch_workflow_logs_flow.serve(
    name="weekly-workflow-report",
    cron="0 3 * * 1",  # 每周一 03:00
    parameters={
        "created_at_after": (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%dT00:00:00Z"),
        "created_at_before": datetime.now().strftime("%Y-%m-%dT00:00:00Z"),
        "output_format": "csv",
        "output_dir": "./outputs/reports/weekly",
        ...
    },
    tags=["weekly", "report"],
)
```

---

## 六、环境变量配置

### 6.1 `.env.example` 模板

```bash
# Dify API 配置
DIFY_BASE_URL=http://localhost
DIFY_API_TOKEN=app-xxxxxxxxxxxxx
DIFY_APP_ID=5ac73990-ee17-4aba-993c-a473e2fa2a90

# Console API 配置（可选）
DIFY_CONSOLE_EMAIL=your-email@example.com
DIFY_CONSOLE_PASSWORD=your-password

# 输出配置
OUTPUT_BASE_DIR=./outputs
STORAGE_TYPE=local  # local/oss/s3

# OSS 配置（如果使用 OSS）
OSS_ENDPOINT=oss-cn-hangzhou.aliyuncs.com
OSS_ACCESS_KEY_ID=xxx
OSS_ACCESS_KEY_SECRET=xxx
OSS_BUCKET_NAME=dify-reports

# 通知配置
NOTIFICATION_ENABLED=true
NOTIFICATION_TYPE=email  # email/dingtalk/wechat

# 邮件通知配置
SMTP_HOST=smtp.example.com
SMTP_PORT=587
SMTP_USER=notifier@example.com
SMTP_PASSWORD=xxx
SMTP_TO=admin@example.com

# 钉钉通知配置
DINGTALK_WEBHOOK=https://oapi.dingtalk.com/robot/send?access_token=xxx

# 日志配置
LOG_LEVEL=INFO
LOG_DIR=./outputs/logs
LOG_RETENTION_DAYS=30

# Prefect 配置
PREFECT_API_URL=http://localhost:4200/api
PREFECT_WORK_POOL_NAME=dify-workflow-pool
```

---

## 七、关键改造点

### 7.1 代码模块化

**当前问题**：
- 所有逻辑在一个 1300+ 行的文件中
- 业务逻辑、配置、输出混在一起

**改造方案**：
1. 将 `WorkflowLogFetcher` 类提取到 `src/services/fetcher.py`
2. 将报告生成逻辑提取到 `src/services/reporter.py`
3. 将配置管理提取到 `src/core/config.py`
4. 将工具函数提取到 `src/utils/`

### 7.2 参数管理

**当前问题**：
- 使用 argparse，参数散落在命令行
- 难以复用和配置

**改造方案**：
1. 使用 Pydantic 进行参数验证和类型检查
2. 支持配置文件（YAML）和环境变量
3. Prefect Flow 参数化，支持 UI 配置

### 7.3 错误处理

**当前问题**：
- 错误处理不够完善
- 缺少重试机制
- 错误信息不够详细

**改造方案**：
1. 定义自定义异常类
2. 实现统一错误处理中间件
3. 集成 Prefect 任务重试
4. 错误通知机制

### 7.4 日志系统

**当前问题**：
- 使用 print 输出，不够结构化
- 缺少日志文件记录
- 难以追踪任务执行历史

**改造方案**：
1. 使用结构化日志库（loguru/structlog）
2. 集成 Prefect 日志系统
3. 日志文件持久化
4. 支持日志查询和分析

### 7.5 结果存储

**当前问题**：
- 结果直接输出到当前目录
- 缺少版本管理
- 没有清理机制

**改造方案**：
1. 统一的存储服务接口
2. 支持多种存储后端
3. 文件命名规范（时间戳+任务ID）
4. 自动清理旧文件

### 7.6 通知机制

**当前问题**：
- 缺少任务完成通知
- 无法及时获知执行结果

**改造方案**：
1. 实现通知服务抽象
2. 支持多种通知渠道
3. 任务成功/失败自动通知
4. 报告生成完成通知

---

## 八、实施步骤

### Phase 1: 基础架构搭建（1-2天）
1. ✅ 创建目录结构
2. ✅ 配置管理模块（ConfigManager）
3. ✅ 日志服务（Logger）
4. ✅ 依赖管理（requirements.txt）

### Phase 2: 服务层重构（2-3天）
1. ✅ 提取 WorkflowLogFetcher 到 services/fetcher.py
2. ✅ 提取报告生成逻辑到 services/reporter.py
3. ✅ 实现 StorageService
4. ✅ 实现 NotificationService

### Phase 3: Prefect 集成（2-3天）
1. ✅ 安装和配置 Prefect
2. ✅ 创建 Flow 和 Task
3. ✅ 实现任务依赖和并发
4. ✅ 配置重试机制

### Phase 4: Deployment 配置（1-2天）
1. ✅ 创建每日报告 Deployment
2. ✅ 创建每周报告 Deployment
3. ✅ 创建自定义报告 Deployment
4. ✅ 配置 Work Pool 和 Worker

### Phase 5: 测试和优化（1-2天）
1. ✅ 单元测试
2. ✅ 集成测试
3. ✅ 性能优化
4. ✅ 文档完善

---

## 九、依赖清单

### 核心依赖
```txt
prefect>=2.14.0
requests>=2.31.0
pydantic>=2.5.0
python-dotenv>=1.0.0
pyyaml>=6.0.1
```

### 可选依赖
```txt
# 日志
loguru>=0.7.2
# 或
structlog>=23.2.0

# 存储
oss2>=2.18.0  # 阿里云 OSS
boto3>=1.29.0  # AWS S3

# 通知
smtplib  # 内置，邮件
requests  # 钉钉/企业微信

# 工具
tenacity>=8.2.3  # 重试库
```

---

## 十、迁移指南

### 10.1 从旧脚本迁移

1. **保留原有功能**：
   - 所有命令行参数功能保持不变
   - 所有业务逻辑保持不变
   - 输出格式保持一致

2. **新增功能**：
   - Prefect 调度和监控
   - 配置管理
   - 通知机制
   - 存储服务

3. **兼容性**：
   - 保留原脚本作为 CLI 工具（向后兼容）
   - 新增 Prefect Flow 作为定时任务入口

### 10.2 配置迁移

将命令行参数映射到配置文件：
```yaml
# config/deployments.yaml
daily_report:
  schedule: "0 2 * * *"
  parameters:
    keyword: null
    status: null
    created_at_after: "{{ yesterday }}"
    created_at_before: "{{ today }}"
    output_format: "csv"
    with_details: true
    with_node_executions: true
```

---

## 十一、监控和运维

### 11.1 Prefect UI 监控

- 任务执行状态
- 执行历史记录
- 参数配置
- 日志查看
- 错误追踪

### 11.2 日志监控

- 结构化日志文件
- 日志轮转和清理
- 错误日志告警

### 11.3 存储监控

- 存储空间使用
- 文件数量统计
- 自动清理机制

---

## 十二、扩展性考虑

### 12.1 多应用支持

- 支持同时监控多个 Dify 应用
- 每个应用独立的配置和调度

### 12.2 多租户支持

- 使用 Prefect 的 tags 和 work pools 隔离
- 独立的存储和通知配置

### 12.3 数据导出扩展

- 支持更多输出格式（Excel、Parquet）
- 支持数据库直接写入
- 支持数据流式处理

---

## 十三、风险评估

### 13.1 技术风险

- **Prefect 学习曲线**：需要团队熟悉 Prefect 概念
- **依赖管理**：新增依赖可能带来兼容性问题
- **迁移成本**：需要测试确保功能一致性

### 13.2 运维风险

- **Prefect Server 可用性**：需要保证 Prefect Server 稳定运行
- **存储空间**：长期运行可能积累大量数据
- **网络依赖**：依赖 Dify API 可用性

### 13.3 缓解措施

- 提供详细文档和培训
- 保留原脚本作为备用方案
- 实现完善的错误处理和重试
- 设置存储清理策略

---

## 十四、验收标准

1. ✅ 所有原有功能正常工作
2. ✅ Prefect Flow 可以正常调度和执行
3. ✅ 配置管理支持环境变量和配置文件
4. ✅ 日志系统正常工作，日志可查询
5. ✅ 通知机制正常工作
6. ✅ 存储服务支持多种后端
7. ✅ 错误处理和重试机制有效
8. ✅ 文档完整，易于维护

---

## 十五、后续优化方向

1. **性能优化**：
   - 并发获取日志
   - 增量数据获取
   - 缓存机制

2. **功能增强**：
   - 数据分析和可视化
   - 异常检测和告警
   - 自动化报告生成

3. **运维增强**：
   - 健康检查接口
   - 指标监控（Prometheus）
   - 分布式执行支持
